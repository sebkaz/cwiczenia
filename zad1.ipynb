{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# klasyczne i kwantowe sieci neuronowe \n",
    "\n",
    "## Wygeneruj klasyczną sieć neuronową dla funckji `sin(x)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import potrzebnych bibliotek \n",
    "\n",
    "import torch\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wygenruj dane:\n",
    "\n",
    "- korzystając z metody torch.linespace() wygenruj 500  punktów danych  dla zakresu (0,10) w tablicy `x`\n",
    "- Ze względu, iz potrzebujemy 500 wierszy przypadków (a nie 500 zmiennych) jednowymiarowej tablicy zastosuj metodę view(-1,1)\n",
    "- jako wynik `si` wygeneruj wartości funckji sin(x). Do zmiennej `y` zastosuj drobną zmianę dodając wartości losowe. \n",
    "- Analogicznie jak dla danych `x` pamiętaj o zmianie widoku : `view(-1,1)`\n",
    "\n",
    "\n",
    "Ponizszy wykres wygeneruje Ci graficzną reprezentację danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### \n",
    "#\n",
    "#  twoj kod \n",
    "x = ...\n",
    "si = ...\n",
    "y = ...\n",
    "\n",
    "x_train = x.requires_grad_(True)\n",
    "#####\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(x, torch.sin(x).view(-1,1), color=\"tab:grey\", alpha=0.6, label=\"sin(x)\")\n",
    "plt.scatter(x,y, label=\"dane treningowe\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korzystając z wartwy gęstej `torch.nn.Linear()`, oraz funkcji aktywacji (np. `torch.nn.ReLU(), torch.nn.Tanh()` i inne) utwórz sieć z kilkoma (przynajmniej jedną warstwą ukrytą) pozwalającą wygenerować model regresji.\n",
    "Do definicji uzyj obiektu `Sequential()` - sprawdź w dokumentacji po co taki obiekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusEstimator(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, N_INPUT: int, N_OUTPUT: int):\n",
    "        super(SinusEstimator,self).__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            # struktura Twojej sieci\n",
    "            torch.nn.Linear(N_INPUT,...),\n",
    "            ...\n",
    "            torch.nn.Linear(...,N_OUTPUT)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniszy kod wytrenuje Twoją sieć:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## \n",
    "# zdefiniuj obiekt modelu. \n",
    "model = ...\n",
    "###########\n",
    "\n",
    "\n",
    "learning_rate=0.001\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# dodatkowa funkcja - warto zrealizować\n",
    "losses = []\n",
    "\n",
    "def callback(model, loss):\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    prediction = model(x).detach()\n",
    "    plt.figure(figsize=(6,2.5))\n",
    "    plt.plot(x[:,0].detach(), torch.sin(x)[:,0].detach(), label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n",
    "    plt.plot(x[:,0].detach(), prediction[:,0], label=\"Classical solution\", color=\"tab:green\")\n",
    "    plt.title(f\"Training step {len(losses)}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6,2.5))\n",
    "    plt.title('Lossfn Visualised')\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(X, Y, model, optimiser, epochs, lossfn, callback = None):\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        prediction = model(X)\n",
    "        loss = lossfn(prediction, Y)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        model.eval()\n",
    "        if callback != None:\n",
    "            callback(model, loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchom funkcję `train()` z odpowiednimi parametrami. \n",
    "\n",
    "- dane: `x_train`, `y`\n",
    "- model sieci: `model`\n",
    "- optymalizator: `optimiser`\n",
    "- ilość epok: `500` (mozesz tez przetestowac najpierw 10 a potem np. 1000)\n",
    "- funkcja straty: `criterion`\n",
    "- callback: nasza zdefiniowana funkcja `callback`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spradz czy inna definicja funkcji kosztu  `special_loss_fn` usprawni wyniki sieci "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_pred) -> torch.Tensor:\n",
    "    return torch.mean((y-y_pred)**2)\n",
    "\n",
    "def special_loss_fn(y, y_pred) -> torch.Tensor:\n",
    "    return mse(y, y_pred) + torch.mean((y_pred - torch.sin(x))**2)\n",
    "\n",
    "train(..........)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kwantowa sieć neuronowa \n",
    "\n",
    "Zdefiniujmy nową strukturę siec - wymieniając warstę ukrytą na obwód kwantowy.\n",
    "```python\n",
    "class QN(nn.Module):\n",
    "    '''Classical -> Quantum -> Classical'''\n",
    "\n",
    "    def __init__(self, N_INPUT: int, N_OUTPUT: int, Q_NODE, N_QUBITS):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            # input layer\n",
    "            nn.Linear(N_INPUT, N_QUBITS),\n",
    "            # 1st hidden layer as a quantum circuit\n",
    "            Q_NODE,\n",
    "            # output layer\n",
    "            nn.Linear(N_QUBITS, N_OUTPUT)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return  self.layers(x)\n",
    "\n",
    "```\n",
    "\n",
    "Jak mozesz zauwazyc po warstwie wejsciowej umiescilismy obietk Q_NODE, którego funkcję podstawimy jako trzeci parametr naszej sieci.\n",
    "\n",
    "Bez większego wchodzenia w definicję tego obiektu nasz obwód kwantowy musi pobrać dane z warstwy poprzedniej i wypuścić jakieś wyniki do warstwy wynikowej. \n",
    "Oczywiście taką operację musi realizować jakaś funkcja (obiekt) w pythonie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # NASZ kwantowy PQC - parametryzowany obwód kwantowy dla jednej warstwy ukrytej\n",
    "import pennylane as qml\n",
    "\n",
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "\n",
    "n_layers = 5\n",
    "\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchomienie sieci mozesz zrealizowac ponizszym kodem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_pred) -> torch.Tensor:\n",
    "    # oblicz średnią z roznnicy y i y_pred podniesionej do kwadratu\n",
    "    return ...\n",
    "\n",
    "\n",
    "#########################\n",
    "#   utworz zmienna qmodel z parametrami (1,1, qlayer, n_qubits)\n",
    "#   Twoj kod\n",
    "#  \n",
    "qmodel = ...\n",
    "#####\n",
    "\n",
    "print(qmodel)\n",
    "\n",
    "x = x.requires_grad_(True)\n",
    "x_train = x.requires_grad_(True)\n",
    "\n",
    "learning_rate=1e-3\n",
    "optimiser = torch.optim.Adam(qmodel.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "def special_loss_fn(y, y_pred) -> torch.Tensor:\n",
    "    return mse(y, y_pred) + torch.mean((y_pred - torch.sin(x))**2)\n",
    "    \n",
    "\n",
    "train(x_train, y, qmodel, optimiser, 500, special_loss_fn, callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdz wyniki kodem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(x,y,x_data,y_data,yh, title=None):\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.title(title)\n",
    "    plt.plot(x,y, color=\"tab:grey\", alpha=0.6, label=\"Exact solution\")\n",
    "    plt.plot(x,yh, color=\"tab:green\", label=\"Neural network prediction\")\n",
    "    plt.scatter(x_data, y_data, alpha=0.3, label='Training data')\n",
    "    l = plt.legend(loc='best')\n",
    "\n",
    "plot_result(\n",
    "    x.detach(),\n",
    "    torch.sin(x).detach(),\n",
    "    x.detach(),\n",
    "    y.detach(),\n",
    "    qmodel(x).detach(),\n",
    "    title='Training of PINN'\n",
    "    )\n",
    "\n",
    "print(mse(qmodel(x), torch.sin(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
